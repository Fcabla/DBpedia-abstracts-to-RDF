# DBpedia abstracts to RDF

## Abstract
This section of the repository comprises the use of generative language tools, such as seq2seq, to extract the possible relationships existing in a document.
In particular, we have tested the use of the REBEL tool, which uses a generative autoregressive seq2seq model.

## 1. Introduction

## 2. Related work

### 2.1 Relation Extraction methods
[REBEL][1]: Relation Extraction By End-to-end Language generation 20 29 by Cabot and Navigli, presented at EMNLP 2021.

The tool that will be mainly explored in this work to extract the relationships between the entities of the same text. It is achieved by using a seq2seq model based on BART.

[GenerativeRE][2]: Incorporating a Novel Copy Mechanism and Pretrained Model for Joint Entity and Relation Extraction 4 by Jiarun Cao, Sophia Ananiadou at EMNLP 2021.

The authors claim that seq2seq models can suffer from incompletion and disorder problems when they extract multi-token entities from input sentences. They propose to use BIO tags before the input representation to improve generation. The model they use is based on transformers. 

[GenIE][3]: Generative Information Extraction 4 by Martin Josifoski, Nicola De Cao, Maxime Peyrard, Robert West.

Another work presenting an end-to-end solution for the extraction of information from a text document using generative methods. 
GenIE uses the BART architecture based on transformers.
To train this model they use the dataset generated by a tool presented in the REBEL paper. This work would be interesting to test and compare with REBEL.

[doc2rel][6]: Giorgi, J., Bader, G. D., & Wang, B. (2022). A sequence-to-sequence approach for document-level relation extraction. arXiv preprint arXiv:2204.01098.

Similar to REBEL, it extends the idea of using seq2seq as a generative model. It is highly specialized in the medical language, so it is not so interesting for our problem.

[GITHUB_REPO][7]: Collection of papers about relation extraction

### 2.2 REBEL aplications

### 2.3 Other resources
[DBpedia forum][4]: Gsoc proyect ideas and proposals

[REBEL repo][5]: github repository

[1]: https://aclanthology.org/2021.findings-emnlp.204.pdf
[2]: https://aclanthology.org/2021.findings-emnlp.182.pdf
[3]: https://arxiv.org/pdf/2112.08340.pdf
[4]: https://forum.dbpedia.org/t/lg2rdf-language-generation-to-generate-rdf-from-dbpedia-abstracts-gsoc2022/1545
[5]: https://github.com/Babelscape/rebel
[6]: https://arxiv.org/pdf/2204.01098.pdf
[7]: https://github.com/roomylee/awesome-relation-extraction
## 3. Approach

Depending on the operations performed before performing inference with the REBEL model, a somewhat different set of results is obtained. In fact, when using the same model from different sources (spacy, hugging faces and transformers) different results can be obtained. After discussing this with the author of the [repository](https://github.com/Babelscape/rebel/issues/41) he confirmed that the sequence of steps up to the inference has a considerable impact on the result.

One of the steps that can be applied and that generate different results is the use of correferences, where the main idea is to replace those terms that refer to an entity by the name of this entity, an example would be the following: 'Although everyone saw the President, no one recognized him'.

Some of the hyperparameters used by the REBEL model are the following: 
- "max_length": 
- "length_penalty": increasing this attribute generates more triples but may increase the model's hallucination.
- "num_beams": mainly affects the quality of the triples but is associated with a higher computational cost.
- "num_return_sequences": 

Another preprocessing that could improve the quality of the output would be to establish an efficient method of splitting long text documents into small chunks or sentences before passing it to the model.

The pipeline consists of a first step where the text document to be translated is read and a series of text processing operations are applied.
Subsequently, the model is fed with the result of the first step of the pipeline and a set of text triples is obtained. These will be given by a subject, a relation and an object with the following format: 'subject|relation|object'.

The next step is to translate the subject and the object of the text triplet into RDF format. To do this, first the DBpedia Spotlight tool will be used to extract the names of the entities recognized in the entire text document. In this way a dictionary with the textual names and their equivalent URIs is obtained, which is used to replace the first and last element of the text triples.

The last step consists of translating the text properties into RDF format. For this we have found no other way than to create a lexicalization, where we have expressly defined what is the RDF equivalent of each type of text property produced by the REBEL model. This last step is far from perfect, as there may be cases in which triples are generated where the domain and range of the relation differ from the class of the subject and object.

## 4. Evaluation
Compare the use of REBEL together with DBpedia Spotlight to the performance we obtained in Gsoc's project and Pablo's TFM.

Since evaluating the quality of the generated triples is a manual and somewhat complicated job, for the moment we will look at the amount of text triples obtained at the end of the pipeline and the amount of RDF triples we can extract from the output generated by the model.

It would be interesting to find a dataset that would be useful for the evaluation of our proposal, so that for each abstract there is a set of triples. Then, we could use our approach to translate that abstract and compare the triples in the dataset with the ones generated by us. We would have to consider the number of triples that match, those that have not been generated and those that have been generated that were not in the dataset.

Aprox 4.89 text triples per abstract with the new approach.
Previous work achieved 7.89 text triples per abstract (Casab√°n Rico)


## 5. Discussion
